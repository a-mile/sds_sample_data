# Combined Data Matrix Generator (GitHub-Linked Version)
# -----------------------------------------------------
# This notebook loads three tabular files and their schemas, normalizes
# their columns, merges them by a common 'primaryIdentifier', and outputs a combined data matrix.

import pandas as pd
import json
import requests
from io import StringIO
import matplotlib.pyplot as plt

# Configuration
BASE_URL = "https://raw.githubusercontent.com/a-mile/sds_sample_data/main/"
DATA_FILES = {
    "histology": {
        "csv": BASE_URL + "histology.csv",
        "schema": BASE_URL + "histology.schema.json"
    },
    "bodyweight": {
        "csv": BASE_URL + "bodyweight.csv",
        "schema": BASE_URL + "bodyweight.schema.json"
    },
    "grip": {
        "csv": BASE_URL + "grip.csv",
        "schema": BASE_URL + "grip.schema.json"
    }
}

def load_schema(url):
    response = requests.get(url)
    response.raise_for_status()
    return json.loads(response.text)

def load_csv(url):
    response = requests.get(url)
    response.raise_for_status()
    return pd.read_csv(StringIO(response.text))

def generate_column_label(assay, role, mapped_name, unit=None, timepoint_unit=None, timepoint=None):
    parts = [assay, role, mapped_name]
    if unit:
        parts.append(unit)
    if timepoint_unit:
        parts.append(timepoint_unit)
    if timepoint is not None:
        parts.append(str(timepoint))
    return ".".join(str(p).replace(" ", "_") for p in parts)

def normalize_dataframe(dataframe, schema, assay):
    primary_id_col = next(f["name"] for f in schema["fields"] if f["custom"]["columnRole"] == "primaryIdentifier")

    normalized = {"sample_id": dataframe[primary_id_col]}

    # Get map of all relatedTo values for derivedFromBiologicalSource
    related_targets = set()
    for field in schema["fields"]:
        relations = field.get("custom", {}).get("relations", [])
        for rel in relations:
            if rel.get("relationType") == "derivedFromBiologicalSource":
                related_targets.update(rel.get("relatedTo", []))

    for field in schema["fields"]:
        role = field.get("custom", {}).get("columnRole")
        name = field["name"]
        mapped_name = field.get("custom", {}).get("mappedDefinition", {}).get("name", name)
        unit = field.get("custom", {}).get("unit")
        timepoint = field.get("custom", {}).get("timepoint")
        timepoint_unit = field.get("custom", {}).get("timepointUnit")

        # Special case: identifier that's a relatedTo target â†’ prefix with "source"
        if role == "identifier" and name in related_targets:
            col_label = f"source.identifier.{mapped_name}"
        else:
            col_label = generate_column_label(assay, role, mapped_name, unit, timepoint_unit, timepoint)

        normalized[col_label] = dataframe[name]

    return pd.DataFrame(normalized)

# Load, normalize, and merge
normalized_dfs = []
for assay, paths in DATA_FILES.items():
    df = load_csv(paths["csv"])
    schema = load_schema(paths["schema"])
    normalized = normalize_dataframe(df, schema, assay)
    normalized_dfs.append(normalized)

# Merge all on sample_id (primaryIdentifier)
from functools import reduce

def merge_dfs_on_sample_id(dfs):
    df = reduce(lambda left, right: pd.merge(left, right, on="sample_id", how="outer"), dfs)
    return df

combined_df = merge_dfs_on_sample_id(normalized_dfs)

# Output to a downloadable location
output_path = "combined_matrix.csv"
combined_df.to_csv(output_path, index=False)
print(f" Combined data matrix written to {output_path}")


# ----------------------------------------
# Visualization Section: Plot Numeric Measures
# ----------------------------------------

# Extract numeric measure columns using schema metadata
numeric_cols = []
for assay, paths in DATA_FILES.items():
    schema = load_schema(paths["schema"])
    for field in schema["fields"]:
        if field["type"] == "number" and field.get("custom", {}).get("columnRole") == "measure":
            mapped_name = field.get("custom", {}).get("mappedDefinition", {}).get("name", field["name"])
            unit = field.get("custom", {}).get("unit")
            timepoint = field.get("custom", {}).get("timepoint")
            timepoint_unit = field.get("custom", {}).get("timepointUnit")
            label = generate_column_label(assay, "measure", mapped_name, unit, timepoint_unit, timepoint)
            numeric_cols.append(label)

# Plot each numeric column
for col in numeric_cols:
    if col in combined_df.columns:
        series = pd.to_numeric(combined_df[col], errors="coerce").dropna()
        if not series.empty:
            series.plot.hist(bins=20, alpha=0.7, title=col)
            plt.xlabel(col)
            plt.ylabel("Count")
            plt.grid(True)
            plt.show()
